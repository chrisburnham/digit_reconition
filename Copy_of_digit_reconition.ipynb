{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of digit_reconition",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisburnham/digit_reconition/blob/master/Copy_of_digit_reconition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBrr5ic0d2VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sKZ3tdDd41J",
        "colab_type": "code",
        "outputId": "ae3d5e1e-5ae9-49f7-a88f-3bb3d10b2d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "# Using https://nextjournal.com/gkoehler/digit-recognition-with-keras\n",
        "# As a starting off point example\n",
        "\n",
        "# imports for array-handling and plotting\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# let's keep our keras backend tensorflow quiet\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "\n",
        "# keras imports for the dataset and building our neural network\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers import Convolution2D as Conv2D\n",
        "from keras.layers import MaxPooling2D, Flatten\n",
        "from keras.utils import np_utils\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# building the input vector from the 28x28 pixels\n",
        "X_train_dense = X_train.reshape(60000, 784)\n",
        "X_test_dense = X_test.reshape(10000, 784)\n",
        "\n",
        "# Adding dimension for convolution\n",
        "X_train_conv = np.expand_dims(X_train, axis=3)\n",
        "X_test_conv = np.expand_dims(X_test, axis=3)\n",
        "\n",
        "# Making types consistent\n",
        "X_train_dense = X_train_dense.astype('float32')\n",
        "X_test_dense = X_test_dense.astype('float32')\n",
        "X_train_conv = X_train_conv.astype('float32')\n",
        "X_test_conv = X_test_conv.astype('float32')\n",
        "\n",
        "\n",
        "# normalizing the data to help with the training\n",
        "X_train_dense /= 255\n",
        "X_test_dense /= 255\n",
        "X_train_conv /= 255\n",
        "X_test_conv /= 255\n",
        "\n",
        "# print the final input shape ready for training\n",
        "print(\"Train dense matrix shape\", X_train_dense.shape)\n",
        "print(\"Test dense matrix shape\", X_test_dense.shape)\n",
        "print(\"Train conv matrix shape\", X_train_conv.shape)\n",
        "print(\"Test conv matrix shape\", X_test_conv.shape)\n",
        "\n",
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", Y_train.shape)\n",
        "\n",
        "# building a linear stack of layers with the sequential model\n",
        "# Model section to do it without convolution\n",
        "model_dense = Sequential()\n",
        "model_dense.add(Dense(512, input_shape=(784,)))\n",
        "model_dense.add(Activation('relu'))                            \n",
        "model_dense.add(Dropout(0.2))\n",
        "\n",
        "model_dense.add(Dense(512))\n",
        "model_dense.add(Activation('relu'))\n",
        "model_dense.add(Dropout(0.2))\n",
        "\n",
        "model_dense.add(Dense(10))\n",
        "model_dense.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# Convolution model\n",
        "model_conv = Sequential()\n",
        "model_conv.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
        "                activation='relu', input_shape=(28, 28, 1)))\n",
        "model_conv.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model_conv.add(Dropout(0.2))\n",
        "\n",
        "model_conv.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))\n",
        "model_conv.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_conv.add(Dropout(0.2))\n",
        "\n",
        "model_conv.add(Flatten())\n",
        "model_conv.add(Dense(512, activation='relu'))\n",
        "\n",
        "model_conv.add(Dense(10))\n",
        "model_conv.add(Activation('softmax'))\n",
        "\n",
        "# compiling the sequential models\n",
        "model_dense.compile(loss='categorical_crossentropy', \n",
        "                    metrics=['accuracy'], \n",
        "                    optimizer='adam')\n",
        "\n",
        "model_conv.compile(loss='categorical_crossentropy', \n",
        "                   metrics=['accuracy'], \n",
        "                   optimizer='adam')\n",
        "\n",
        "\n",
        "# training the model and saving metrics in history\n",
        "history_dense = model.fit(X_train_dense, Y_train,\n",
        "                          batch_size=128, epochs=20,\n",
        "                          verbose=2,\n",
        "                          validation_data=(X_test_dense, Y_test))\n",
        "\n",
        "# plotting the metrics\n",
        "fig_dense = plt.figure()\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history_dense.history['acc'])\n",
        "plt.plot(history_dense.history['val_acc'])\n",
        "plt.title('dense model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history_dense.history['loss'])\n",
        "plt.plot(history_dense.history['val_loss'])\n",
        "plt.title('dense model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "fig_dense\n",
        "\n",
        "# training the model and saving metrics in history\n",
        "history_conv = model.fit(X_train_conv, Y_train,\n",
        "                         batch_size=128, epochs=20,\n",
        "                         verbose=2,\n",
        "                         validation_data=(X_test_conv, Y_test))\n",
        "\n",
        "# plotting the metrics\n",
        "fig_conv = plt.figure()\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history_conv.history['acc'])\n",
        "plt.plot(history_conv.history['val_acc'])\n",
        "plt.title('convolution model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history_conv.history['loss'])\n",
        "plt.plot(history_conv.history['val_loss'])\n",
        "plt.title('convolution model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "fig_conv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "Train matrix shape (60000, 28, 28, 1)\n",
            "Test matrix shape (10000, 28, 28, 1)\n",
            "Shape before one-hot encoding:  (60000,)\n",
            "Shape after one-hot encoding:  (60000, 10)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            " - 80s - loss: 0.1845 - acc: 0.9438 - val_loss: 0.0459 - val_acc: 0.9857\n",
            "Epoch 2/20\n",
            " - 78s - loss: 0.0544 - acc: 0.9831 - val_loss: 0.0327 - val_acc: 0.9892\n",
            "Epoch 3/20\n",
            " - 78s - loss: 0.0390 - acc: 0.9873 - val_loss: 0.0278 - val_acc: 0.9920\n",
            "Epoch 4/20\n",
            " - 78s - loss: 0.0301 - acc: 0.9904 - val_loss: 0.0241 - val_acc: 0.9910\n",
            "Epoch 5/20\n",
            " - 79s - loss: 0.0253 - acc: 0.9916 - val_loss: 0.0224 - val_acc: 0.9916\n",
            "Epoch 6/20\n",
            " - 79s - loss: 0.0214 - acc: 0.9935 - val_loss: 0.0269 - val_acc: 0.9921\n",
            "Epoch 7/20\n",
            " - 79s - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0267 - val_acc: 0.9910\n",
            "Epoch 8/20\n",
            " - 80s - loss: 0.0162 - acc: 0.9949 - val_loss: 0.0245 - val_acc: 0.9927\n",
            "Epoch 9/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OfNBtqyY5XP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}